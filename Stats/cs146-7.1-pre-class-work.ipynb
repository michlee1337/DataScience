{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The `electoral_votes` variable is a dictionary containing the number of Electoral College votes for each state. For example\n",
    "```\n",
    "  >>> electoral_votes['Indiana']\n",
    "  11\n",
    "```\n",
    "Data from [Wikipedia: United_States_Electoral_College](https://en.wikipedia.org/wiki/United_States_Electoral_College)\n",
    "\n",
    "The `survey_results` variable is a dictionary mapping from states to an array of survey results for each candidate. Each row in a survey results array represents one survey and each column represents one candidate. There are 4 columns, representing Clinton, Trump, Johnson, and Stein in that order. In the example below, Clinton got 340 votes in the first survey, Trump got 258, Johnson got 27, and Stein got 13.\n",
    "```\n",
    "  >>> survey_results['Indiana']\n",
    "  array([[340, 258,  27,  13],\n",
    "         [240, 155,   5,   5],\n",
    "         [235, 155,  50,  20],\n",
    "         [308, 266,  49,  35],\n",
    "         [222, 161,  80,  30]])\n",
    "```\n",
    "Data from [Wikipedia: Statewide opinion polling for the United States presidential election, 2016](https://en.wikipedia.org/wiki/Statewide_opinion_polling_for_the_United_States_presidential_election,_2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling 5 states with 38 electoral college votes\n"
     ]
    }
   ],
   "source": [
    "electoral_votes = {\n",
    "    'Alabama': 9,\n",
    "    'Alaska': 3,\n",
    "    'Arizona': 11,\n",
    "    'Arkansas': 6,\n",
    "    'Colorado': 9,\n",
    "}\n",
    "\n",
    "survey_results = {\n",
    "    'Alabama': np.array([], dtype=int).reshape(0, 4),\n",
    "    'Alaska': np.array([400 * np.array([.47, .43, .07, .03]), 500 * np.array([.36, .37, .07, .03]), 500 * np.array([.34, .37, .10, .02]), 660 * np.array([.31, .36, .18, .06])], dtype=int),\n",
    "    'Arizona': np.array([392 * np.array([.45, .47, .05, .02]), 550 * np.array([.39, .47, .04, .03]), 719 * np.array([.40, .45, .09, .03]), 769 * np.array([.44, .49, .05, .01]), 2229 * np.array([.45, .44, .07, .01]), 700 * np.array([.43, .47, .02, .02]), 550 * np.array([.41, .45, .03, .01]), 994 * np.array([.42, .44, .04, .01]), 550 * np.array([.40, .42, .05, .02]), 2385 * np.array([.48, .46, .05, .01]), 401 * np.array([.45, .46, .04, .01]), 550 * np.array([.41, .41, .05, .02]), 1538 * np.array([.39, .44, .06, .02]), 713 * np.array([.43, .38, .06, .01]), 400 * np.array([.39, .37, .08, .03]), 600 * np.array([.44, .42, .09, .01]), 718 * np.array([.42, .42, .05, .01]), 484 * np.array([.41, .46, .09, .01]), 649 * np.array([.38, .40, .12, .03])], dtype=int),\n",
    "    'Arkansas': np.array([463 * np.array([.33, .56, .04, .02]), 831 * np.array([.34, .55, .03, .01]), 600 * np.array([.29, .57, .05, .03])], dtype=int),\n",
    "    'Colorado': np.array([1150 * np.array([.45, .44, .05, .04]), 500 * np.array([.44, .38, .07, .02]), 550 * np.array([.39, .39, .05, .04]), 750 * np.array([.44, .41, .08, .04]), 685 * np.array([.45, .37, .10, .03]), 400 * np.array([.49, .38, .07, .03]), 602 * np.array([.44, .33, .10, .03]), 694 * np.array([.46, .40, .06, .02]), 784 * np.array([.41, .42, .13, .03]), 991 * np.array([.40, .39, .07, .02]), 644 * np.array([.44, .42, .10, .02]), 540 * np.array([.41, .34, .12, .03]), 600 * np.array([.38, .42, .13, .02]), 704 * np.array([.48, .43, .04, .02]), 605 * np.array([.43, .38, .07, .02]), 997 * np.array([.42, .39, .07, .02])], dtype=int),\n",
    "}\n",
    "\n",
    "states = sorted(survey_results.keys())\n",
    "print('Modeling', len(states), 'states with', sum(electoral_votes[s] for s in states), 'electoral college votes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative model\n",
    "\n",
    "1. For each state we generate an $\\vec{\\alpha}$ vector, which defines a Dirichlet distribution over the proportion of votes that go to each of the 4 candidates whenever we do a survey — including the final survey, namely the election itself which we want to predict. The prior over each component of $\\vec{\\alpha}$ is taken as a Cauchy distribution with location 0 and scale 1. Since the components of $\\vec{\\alpha}$ are positive, we actually use the positive half-Cauchy distribution.\n",
    "\n",
    "2. For each survey in a state we generate a probability vector $\\vec{p_i} \\sim \\text{Dirichlet}(\\vec{\\alpha})$ for the probability that a voter selects each of the 4 candidates.\n",
    "\n",
    "3. For each survey, we then generate the number of votes going to each candidate as $\\vec{k_i} \\sim \\text{Multinomial}(\\vec{p_i})$.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* Use Stan to sample from the posterior distribution over $\\alpha$ and visualize your results. There are 10 states, so you will have 10 posteriors.\n",
    "* The posteriors over $\\alpha$ show a lot of variation between different states. Explain the results you get in terms of the model and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_code = '''\n",
    "data {\n",
    "}\n",
    "\n",
    "parameters {\n",
    "}\n",
    "\n",
    "model {        \n",
    "        \n",
    "    for i in 1:sur_count {\n",
    "        for j in 1:cand_count {\n",
    "            vector[i*j] ~ cauchy(0, 1)\n",
    "        }\n",
    "    }\n",
    "        \n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "stan_model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation time\n",
    "\n",
    "Use the posterior samples to predict the outcome of the presidential elections.\n",
    "\n",
    "* Predict the probability that each candidate will win each state.\n",
    "   * Use the posterior $\\alpha$ samples to generate posterior predictive samples for $p$ — the proportion of votes each candidate would get in each state in an election.\n",
    "   * Use these $p$ samples to estimate the probability that each candidate will win each state.\n",
    "* Predict the probability that each candidate will win the presidential election.\n",
    "   * Use the posterior predictive probability that each candidate will win each state to generate samples over the total number Electoral College votes each candidate would get in an election.\n",
    "   * Use the total number of votes to generate samples over who would win the election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
